{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bb2b44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0210f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-20 16:27:39.371713: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-20 16:27:39.371961: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-20 16:27:39.409944: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/sirin/BIGDATA/.venv/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/attr_value.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/sirin/BIGDATA/.venv/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/sirin/BIGDATA/.venv/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/resource_handle.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/sirin/BIGDATA/.venv/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_shape.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/sirin/BIGDATA/.venv/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/types.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/sirin/BIGDATA/.venv/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/full_type.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/sirin/BIGDATA/.venv/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/function.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/sirin/BIGDATA/.venv/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/node_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/sirin/BIGDATA/.venv/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/op_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/sirin/BIGDATA/.venv/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/sirin/BIGDATA/.venv/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph_debug_info.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/sirin/BIGDATA/.venv/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/versions.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/sirin/BIGDATA/.venv/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/sirin/BIGDATA/.venv/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at xla/tsl/protobuf/coordination_config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/sirin/BIGDATA/.venv/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/cost_graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/sirin/BIGDATA/.venv/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/step_stats.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/sirin/BIGDATA/.venv/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/allocation_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/sirin/BIGDATA/.venv/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/sirin/BIGDATA/.venv/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/cluster.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/home/sirin/BIGDATA/.venv/lib/python3.12/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/debug.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "2025-11-20 16:27:40.461072: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-20 16:27:40.461345: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-20 16:27:40.461072: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-20 16:27:40.461345: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.20.0\n",
      "GPU Available: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1763630861.577992    5853 cuda_executor.cc:1309] INTERNAL: CUDA Runtime error: Failed call to cudaGetRuntimeVersion: Error loading CUDA libraries. GPU will not be used.: Error loading CUDA libraries. GPU will not be used.\n",
      "W0000 00:00:1763630861.584689    5853 gpu_device.cc:2342] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "import json\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "\n",
    "# Deep learning libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU Available: {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bc58ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickup file: /home/sirin/BIGDATA/pickup_five_cities.csv\n",
      "Delivery file: /home/sirin/BIGDATA/delivery_five_cities.csv\n",
      "Output path: /home/sirin/BIGDATA/quick-result\n",
      "Output directory exists: True\n"
     ]
    }
   ],
   "source": [
    "# Define paths\n",
    "BASE_PATH = '/home/sirin/BIGDATA'\n",
    "PICKUP_FILE = os.path.join(BASE_PATH, 'pickup_five_cities.csv')\n",
    "DELIVERY_FILE = os.path.join(BASE_PATH, 'delivery_five_cities.csv')\n",
    "OUTPUT_PATH = os.path.join(BASE_PATH, 'quick-result')\n",
    "\n",
    "# Create output directory if not exists\n",
    "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
    "\n",
    "print(f\"Pickup file: {PICKUP_FILE}\")\n",
    "print(f\"Delivery file: {DELIVERY_FILE}\")\n",
    "print(f\"Output path: {OUTPUT_PATH}\")\n",
    "print(f\"Output directory exists: {os.path.exists(OUTPUT_PATH)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5c3ecd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pickup data...\n",
      "Pickup data shape: (531115, 19)\n",
      "Pickup columns: ['order_id', 'from_dipan_id', 'from_city_name', 'delivery_user_id', 'accept_time', 'book_start_time', 'expect_got_time', 'poi_lng', 'poi_lat', 'aoi_id', 'typecode', 'got_time', 'got_gps_time', 'got_gps_lng', 'got_gps_lat', 'accept_gps_time', 'accept_gps_lng', 'accept_gps_lat', 'ds']\n",
      "                           order_id                     from_dipan_id  \\\n",
      "0  8602ab9c07a2c499b52688a743b6e4bc  4221488252e767b1d0bc82a72053d43d   \n",
      "1  d35cb23e9a4ebd887d85add85efb1db4  3bde1f883391f1bebb487666edea1776   \n",
      "2  1bf13df5b9cfabe528ff11e252989bc2  8d07525f08cd28bb54e44805dd5d66c7   \n",
      "3  a85d1f24fda72f6b863585d58092f9a6  255ab20fe675f4bf9e2907b45f940b81   \n",
      "4  3e6cac7405dc999a17655505396f283c  0734207f2cdd486857508c2ab8a9e05f   \n",
      "\n",
      "  from_city_name                  delivery_user_id     accept_time  \\\n",
      "0            杭州市  135bdc6219e9f1b5867d0d3cbfc159e5  03-19 07:25:00   \n",
      "1            杭州市  4557a4c27997fe5817136fc1023f741e  03-19 07:55:00   \n",
      "2            烟台市  42e6bc48a505ffb4ff9e799cb70fb372  03-19 13:11:00   \n",
      "3            杭州市  32bdfe340b8be76dbf9435c35e87754b  03-19 10:14:00   \n",
      "4            上海市  f133f7a7cedf0ac38a12c1582d12201d  03-19 08:11:00   \n",
      "\n",
      "  book_start_time expect_got_time       poi_lng       poi_lat  \\\n",
      "0  03-19 09:00:00  03-19 11:00:00  1.043691e+07 -7.577244e+06   \n",
      "1  03-19 09:00:00  03-19 11:00:00  1.041147e+07 -7.593134e+06   \n",
      "2  03-19 15:00:00  03-19 17:00:00  1.040373e+07 -6.667527e+06   \n",
      "3  03-19 13:00:00  03-19 15:00:00  1.041120e+07 -7.617361e+06   \n",
      "4  03-19 09:00:00  03-19 11:00:00  1.055947e+07 -7.458202e+06   \n",
      "\n",
      "                             aoi_id                          typecode  \\\n",
      "0  a77eccfcfd2ab40c1a6ab4a32afe140e  203ac3454d75e02ebb0a3c6f51d735e4   \n",
      "1  fa03dccbaa72d88410beb91e59d60907  14cca3f2714c7c0faf2cbac10ba12d3b   \n",
      "2  59987b5f0962b280684423af9b778200  203ac3454d75e02ebb0a3c6f51d735e4   \n",
      "3  2a7725902487ca096f881b3f20212f05  203ac3454d75e02ebb0a3c6f51d735e4   \n",
      "4  f8c5b8a82c2c9623ae89c068deb3940d  203ac3454d75e02ebb0a3c6f51d735e4   \n",
      "\n",
      "         got_time got_gps_time  got_gps_lng  got_gps_lat accept_gps_time  \\\n",
      "0  03-19 09:20:00          NaN          NaN          NaN             NaN   \n",
      "1  03-19 10:08:00          NaN          NaN          NaN             NaN   \n",
      "2  03-19 14:06:00          NaN          NaN          NaN             NaN   \n",
      "3  03-19 10:33:00          NaN          NaN          NaN             NaN   \n",
      "4  03-19 09:49:00          NaN          NaN          NaN             NaN   \n",
      "\n",
      "   accept_gps_lng  accept_gps_lat   ds  \n",
      "0             NaN             NaN  319  \n",
      "1             NaN             NaN  319  \n",
      "2             NaN             NaN  319  \n",
      "3             NaN             NaN  319  \n",
      "4             NaN             NaN  319  \n",
      "\n",
      "Loading delivery data...\n",
      "Pickup data shape: (531115, 19)\n",
      "Pickup columns: ['order_id', 'from_dipan_id', 'from_city_name', 'delivery_user_id', 'accept_time', 'book_start_time', 'expect_got_time', 'poi_lng', 'poi_lat', 'aoi_id', 'typecode', 'got_time', 'got_gps_time', 'got_gps_lng', 'got_gps_lat', 'accept_gps_time', 'accept_gps_lng', 'accept_gps_lat', 'ds']\n",
      "                           order_id                     from_dipan_id  \\\n",
      "0  8602ab9c07a2c499b52688a743b6e4bc  4221488252e767b1d0bc82a72053d43d   \n",
      "1  d35cb23e9a4ebd887d85add85efb1db4  3bde1f883391f1bebb487666edea1776   \n",
      "2  1bf13df5b9cfabe528ff11e252989bc2  8d07525f08cd28bb54e44805dd5d66c7   \n",
      "3  a85d1f24fda72f6b863585d58092f9a6  255ab20fe675f4bf9e2907b45f940b81   \n",
      "4  3e6cac7405dc999a17655505396f283c  0734207f2cdd486857508c2ab8a9e05f   \n",
      "\n",
      "  from_city_name                  delivery_user_id     accept_time  \\\n",
      "0            杭州市  135bdc6219e9f1b5867d0d3cbfc159e5  03-19 07:25:00   \n",
      "1            杭州市  4557a4c27997fe5817136fc1023f741e  03-19 07:55:00   \n",
      "2            烟台市  42e6bc48a505ffb4ff9e799cb70fb372  03-19 13:11:00   \n",
      "3            杭州市  32bdfe340b8be76dbf9435c35e87754b  03-19 10:14:00   \n",
      "4            上海市  f133f7a7cedf0ac38a12c1582d12201d  03-19 08:11:00   \n",
      "\n",
      "  book_start_time expect_got_time       poi_lng       poi_lat  \\\n",
      "0  03-19 09:00:00  03-19 11:00:00  1.043691e+07 -7.577244e+06   \n",
      "1  03-19 09:00:00  03-19 11:00:00  1.041147e+07 -7.593134e+06   \n",
      "2  03-19 15:00:00  03-19 17:00:00  1.040373e+07 -6.667527e+06   \n",
      "3  03-19 13:00:00  03-19 15:00:00  1.041120e+07 -7.617361e+06   \n",
      "4  03-19 09:00:00  03-19 11:00:00  1.055947e+07 -7.458202e+06   \n",
      "\n",
      "                             aoi_id                          typecode  \\\n",
      "0  a77eccfcfd2ab40c1a6ab4a32afe140e  203ac3454d75e02ebb0a3c6f51d735e4   \n",
      "1  fa03dccbaa72d88410beb91e59d60907  14cca3f2714c7c0faf2cbac10ba12d3b   \n",
      "2  59987b5f0962b280684423af9b778200  203ac3454d75e02ebb0a3c6f51d735e4   \n",
      "3  2a7725902487ca096f881b3f20212f05  203ac3454d75e02ebb0a3c6f51d735e4   \n",
      "4  f8c5b8a82c2c9623ae89c068deb3940d  203ac3454d75e02ebb0a3c6f51d735e4   \n",
      "\n",
      "         got_time got_gps_time  got_gps_lng  got_gps_lat accept_gps_time  \\\n",
      "0  03-19 09:20:00          NaN          NaN          NaN             NaN   \n",
      "1  03-19 10:08:00          NaN          NaN          NaN             NaN   \n",
      "2  03-19 14:06:00          NaN          NaN          NaN             NaN   \n",
      "3  03-19 10:33:00          NaN          NaN          NaN             NaN   \n",
      "4  03-19 09:49:00          NaN          NaN          NaN             NaN   \n",
      "\n",
      "   accept_gps_lng  accept_gps_lat   ds  \n",
      "0             NaN             NaN  319  \n",
      "1             NaN             NaN  319  \n",
      "2             NaN             NaN  319  \n",
      "3             NaN             NaN  319  \n",
      "4             NaN             NaN  319  \n",
      "\n",
      "Loading delivery data...\n",
      "Delivery data shape: (472419, 15)\n",
      "Delivery columns: ['order_id', 'from_dipan_id', 'from_city_name', 'delivery_user_id', 'poi_lng', 'poi_lat', 'aoi_id', 'typecode', 'receipt_time', 'receipt_lng', 'receipt_lat', 'sign_time', 'sign_lng', 'sign_lat', 'ds']\n",
      "                           order_id                     from_dipan_id  \\\n",
      "0  687227b4d0c733049b16ccd566db6e01  08331170e24742ba7a3938f5b34ff24d   \n",
      "1  55be8cdf1270526231c9ba3387f51b54  c5ac5ba99801aa6b85ba473d9260512b   \n",
      "2  ee46cae9ba2c002451af3c6fbcb49410  2129bfb99a2f6c11000c0ecbf1a5f3f6   \n",
      "3  38912be86c83138901b5e26398832be7  08331170e24742ba7a3938f5b34ff24d   \n",
      "4  2b83e2ba16714fee357694964d0e7e41  4fe96250270c2e17a28016a5fba4bc4a   \n",
      "\n",
      "  from_city_name                  delivery_user_id       poi_lng  \\\n",
      "0            上海市  18ff78d2069125937a847fb701a9db6c  1.056351e+07   \n",
      "1            重庆市  df0b594618d1ba6f619e4e7dd034447c  8.899874e+06   \n",
      "2            上海市  05cceaaa5db96756294dd6d573fd865d  1.058131e+07   \n",
      "3            上海市  f29e97ef8398477abb72b852b16c91c0  1.056273e+07   \n",
      "4            杭州市  1d00e6f2308aad233f0179aac63aa23d  1.044847e+07   \n",
      "\n",
      "        poi_lat                            aoi_id  \\\n",
      "0 -7.458321e+06  e0581ca18e7ca371a9869e041cb09075   \n",
      "1 -7.684936e+06  9c0f96ff01a71477334ef563001abc72   \n",
      "2 -7.467397e+06  4de9bf7f155046e7d0fd400672ab9cf3   \n",
      "3 -7.456804e+06  fe48cde9b33e2308641d985f8a701c7e   \n",
      "4 -7.587086e+06  a7d4de5484ca867fe453976ba9fee424   \n",
      "\n",
      "                           typecode    receipt_time   receipt_lng  \\\n",
      "0  4602b38053ece07a9ca5153f1df2e404  03-18 13:35:00  1.056160e+07   \n",
      "1  203ac3454d75e02ebb0a3c6f51d735e4  03-18 08:32:00  8.900992e+06   \n",
      "2  203ac3454d75e02ebb0a3c6f51d735e4  03-18 13:02:00  1.058124e+07   \n",
      "3  203ac3454d75e02ebb0a3c6f51d735e4  03-18 12:11:00  1.056160e+07   \n",
      "4  4602b38053ece07a9ca5153f1df2e404  03-18 07:28:00  1.044791e+07   \n",
      "\n",
      "    receipt_lat       sign_time  sign_lng  sign_lat   ds  \n",
      "0 -7.457998e+06  03-18 14:51:00       NaN       NaN  318  \n",
      "1 -7.686103e+06  03-18 14:33:00       NaN       NaN  318  \n",
      "2 -7.467607e+06  03-18 15:34:00       NaN       NaN  318  \n",
      "3 -7.457997e+06  03-18 14:08:00       NaN       NaN  318  \n",
      "4 -7.586259e+06  03-20 12:40:00       NaN       NaN  318  \n",
      "Delivery data shape: (472419, 15)\n",
      "Delivery columns: ['order_id', 'from_dipan_id', 'from_city_name', 'delivery_user_id', 'poi_lng', 'poi_lat', 'aoi_id', 'typecode', 'receipt_time', 'receipt_lng', 'receipt_lat', 'sign_time', 'sign_lng', 'sign_lat', 'ds']\n",
      "                           order_id                     from_dipan_id  \\\n",
      "0  687227b4d0c733049b16ccd566db6e01  08331170e24742ba7a3938f5b34ff24d   \n",
      "1  55be8cdf1270526231c9ba3387f51b54  c5ac5ba99801aa6b85ba473d9260512b   \n",
      "2  ee46cae9ba2c002451af3c6fbcb49410  2129bfb99a2f6c11000c0ecbf1a5f3f6   \n",
      "3  38912be86c83138901b5e26398832be7  08331170e24742ba7a3938f5b34ff24d   \n",
      "4  2b83e2ba16714fee357694964d0e7e41  4fe96250270c2e17a28016a5fba4bc4a   \n",
      "\n",
      "  from_city_name                  delivery_user_id       poi_lng  \\\n",
      "0            上海市  18ff78d2069125937a847fb701a9db6c  1.056351e+07   \n",
      "1            重庆市  df0b594618d1ba6f619e4e7dd034447c  8.899874e+06   \n",
      "2            上海市  05cceaaa5db96756294dd6d573fd865d  1.058131e+07   \n",
      "3            上海市  f29e97ef8398477abb72b852b16c91c0  1.056273e+07   \n",
      "4            杭州市  1d00e6f2308aad233f0179aac63aa23d  1.044847e+07   \n",
      "\n",
      "        poi_lat                            aoi_id  \\\n",
      "0 -7.458321e+06  e0581ca18e7ca371a9869e041cb09075   \n",
      "1 -7.684936e+06  9c0f96ff01a71477334ef563001abc72   \n",
      "2 -7.467397e+06  4de9bf7f155046e7d0fd400672ab9cf3   \n",
      "3 -7.456804e+06  fe48cde9b33e2308641d985f8a701c7e   \n",
      "4 -7.587086e+06  a7d4de5484ca867fe453976ba9fee424   \n",
      "\n",
      "                           typecode    receipt_time   receipt_lng  \\\n",
      "0  4602b38053ece07a9ca5153f1df2e404  03-18 13:35:00  1.056160e+07   \n",
      "1  203ac3454d75e02ebb0a3c6f51d735e4  03-18 08:32:00  8.900992e+06   \n",
      "2  203ac3454d75e02ebb0a3c6f51d735e4  03-18 13:02:00  1.058124e+07   \n",
      "3  203ac3454d75e02ebb0a3c6f51d735e4  03-18 12:11:00  1.056160e+07   \n",
      "4  4602b38053ece07a9ca5153f1df2e404  03-18 07:28:00  1.044791e+07   \n",
      "\n",
      "    receipt_lat       sign_time  sign_lng  sign_lat   ds  \n",
      "0 -7.457998e+06  03-18 14:51:00       NaN       NaN  318  \n",
      "1 -7.686103e+06  03-18 14:33:00       NaN       NaN  318  \n",
      "2 -7.467607e+06  03-18 15:34:00       NaN       NaN  318  \n",
      "3 -7.457997e+06  03-18 14:08:00       NaN       NaN  318  \n",
      "4 -7.586259e+06  03-20 12:40:00       NaN       NaN  318  \n"
     ]
    }
   ],
   "source": [
    "# Load data with chunking to handle large files\n",
    "print(\"Loading pickup data...\")\n",
    "pickup_df = pd.read_csv(PICKUP_FILE, dtype={'from_city_name': 'category', 'typecode': 'category'})\n",
    "print(f\"Pickup data shape: {pickup_df.shape}\")\n",
    "print(f\"Pickup columns: {pickup_df.columns.tolist()}\")\n",
    "print(pickup_df.head())\n",
    "\n",
    "print(\"\\nLoading delivery data...\")\n",
    "delivery_df = pd.read_csv(DELIVERY_FILE, dtype={'from_city_name': 'category', 'typecode': 'category'})\n",
    "print(f\"Delivery data shape: {delivery_df.shape}\")\n",
    "print(f\"Delivery columns: {delivery_df.columns.tolist()}\")\n",
    "print(delivery_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9d335d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing data...\n",
      "Processed pickup data shape: (531115, 21)\n",
      "Processed delivery data shape: (472419, 17)\n",
      "\n",
      "Processed pickup sample:\n",
      "                           order_id                     from_dipan_id  \\\n",
      "0  8602ab9c07a2c499b52688a743b6e4bc  4221488252e767b1d0bc82a72053d43d   \n",
      "1  d35cb23e9a4ebd887d85add85efb1db4  3bde1f883391f1bebb487666edea1776   \n",
      "2  1bf13df5b9cfabe528ff11e252989bc2  8d07525f08cd28bb54e44805dd5d66c7   \n",
      "3  a85d1f24fda72f6b863585d58092f9a6  255ab20fe675f4bf9e2907b45f940b81   \n",
      "4  3e6cac7405dc999a17655505396f283c  0734207f2cdd486857508c2ab8a9e05f   \n",
      "\n",
      "  from_city_name                  delivery_user_id         accept_time  \\\n",
      "0            杭州市  135bdc6219e9f1b5867d0d3cbfc159e5 1900-03-19 07:25:00   \n",
      "1            杭州市  4557a4c27997fe5817136fc1023f741e 1900-03-19 07:55:00   \n",
      "2            烟台市  42e6bc48a505ffb4ff9e799cb70fb372 1900-03-19 13:11:00   \n",
      "3            杭州市  32bdfe340b8be76dbf9435c35e87754b 1900-03-19 10:14:00   \n",
      "4            上海市  f133f7a7cedf0ac38a12c1582d12201d 1900-03-19 08:11:00   \n",
      "\n",
      "      book_start_time     expect_got_time       poi_lng       poi_lat  \\\n",
      "0 1900-03-19 09:00:00 1900-03-19 11:00:00  1.043691e+07 -7.577244e+06   \n",
      "1 1900-03-19 09:00:00 1900-03-19 11:00:00  1.041147e+07 -7.593134e+06   \n",
      "2 1900-03-19 15:00:00 1900-03-19 17:00:00  1.040373e+07 -6.667527e+06   \n",
      "3 1900-03-19 13:00:00 1900-03-19 15:00:00  1.041120e+07 -7.617361e+06   \n",
      "4 1900-03-19 09:00:00 1900-03-19 11:00:00  1.055947e+07 -7.458202e+06   \n",
      "\n",
      "                             aoi_id  ...            got_time got_gps_time  \\\n",
      "0  a77eccfcfd2ab40c1a6ab4a32afe140e  ... 1900-03-19 09:20:00          NaN   \n",
      "1  fa03dccbaa72d88410beb91e59d60907  ... 1900-03-19 10:08:00          NaN   \n",
      "2  59987b5f0962b280684423af9b778200  ... 1900-03-19 14:06:00          NaN   \n",
      "3  2a7725902487ca096f881b3f20212f05  ... 1900-03-19 10:33:00          NaN   \n",
      "4  f8c5b8a82c2c9623ae89c068deb3940d  ... 1900-03-19 09:49:00          NaN   \n",
      "\n",
      "    got_gps_lng   got_gps_lat  accept_gps_time accept_gps_lng  accept_gps_lat  \\\n",
      "0  1.042869e+07 -7.577123e+06              NaN            NaN             NaN   \n",
      "1  1.042869e+07 -7.577123e+06              NaN            NaN             NaN   \n",
      "2  1.042869e+07 -7.577123e+06              NaN            NaN             NaN   \n",
      "3  1.042869e+07 -7.577123e+06              NaN            NaN             NaN   \n",
      "4  1.042869e+07 -7.577123e+06              NaN            NaN             NaN   \n",
      "\n",
      "    ds  accept_hour  accept_minute  \n",
      "0  319            7             25  \n",
      "1  319            7             55  \n",
      "2  319           13             11  \n",
      "3  319           10             14  \n",
      "4  319            8             11  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "Processed pickup data shape: (531115, 21)\n",
      "Processed delivery data shape: (472419, 17)\n",
      "\n",
      "Processed pickup sample:\n",
      "                           order_id                     from_dipan_id  \\\n",
      "0  8602ab9c07a2c499b52688a743b6e4bc  4221488252e767b1d0bc82a72053d43d   \n",
      "1  d35cb23e9a4ebd887d85add85efb1db4  3bde1f883391f1bebb487666edea1776   \n",
      "2  1bf13df5b9cfabe528ff11e252989bc2  8d07525f08cd28bb54e44805dd5d66c7   \n",
      "3  a85d1f24fda72f6b863585d58092f9a6  255ab20fe675f4bf9e2907b45f940b81   \n",
      "4  3e6cac7405dc999a17655505396f283c  0734207f2cdd486857508c2ab8a9e05f   \n",
      "\n",
      "  from_city_name                  delivery_user_id         accept_time  \\\n",
      "0            杭州市  135bdc6219e9f1b5867d0d3cbfc159e5 1900-03-19 07:25:00   \n",
      "1            杭州市  4557a4c27997fe5817136fc1023f741e 1900-03-19 07:55:00   \n",
      "2            烟台市  42e6bc48a505ffb4ff9e799cb70fb372 1900-03-19 13:11:00   \n",
      "3            杭州市  32bdfe340b8be76dbf9435c35e87754b 1900-03-19 10:14:00   \n",
      "4            上海市  f133f7a7cedf0ac38a12c1582d12201d 1900-03-19 08:11:00   \n",
      "\n",
      "      book_start_time     expect_got_time       poi_lng       poi_lat  \\\n",
      "0 1900-03-19 09:00:00 1900-03-19 11:00:00  1.043691e+07 -7.577244e+06   \n",
      "1 1900-03-19 09:00:00 1900-03-19 11:00:00  1.041147e+07 -7.593134e+06   \n",
      "2 1900-03-19 15:00:00 1900-03-19 17:00:00  1.040373e+07 -6.667527e+06   \n",
      "3 1900-03-19 13:00:00 1900-03-19 15:00:00  1.041120e+07 -7.617361e+06   \n",
      "4 1900-03-19 09:00:00 1900-03-19 11:00:00  1.055947e+07 -7.458202e+06   \n",
      "\n",
      "                             aoi_id  ...            got_time got_gps_time  \\\n",
      "0  a77eccfcfd2ab40c1a6ab4a32afe140e  ... 1900-03-19 09:20:00          NaN   \n",
      "1  fa03dccbaa72d88410beb91e59d60907  ... 1900-03-19 10:08:00          NaN   \n",
      "2  59987b5f0962b280684423af9b778200  ... 1900-03-19 14:06:00          NaN   \n",
      "3  2a7725902487ca096f881b3f20212f05  ... 1900-03-19 10:33:00          NaN   \n",
      "4  f8c5b8a82c2c9623ae89c068deb3940d  ... 1900-03-19 09:49:00          NaN   \n",
      "\n",
      "    got_gps_lng   got_gps_lat  accept_gps_time accept_gps_lng  accept_gps_lat  \\\n",
      "0  1.042869e+07 -7.577123e+06              NaN            NaN             NaN   \n",
      "1  1.042869e+07 -7.577123e+06              NaN            NaN             NaN   \n",
      "2  1.042869e+07 -7.577123e+06              NaN            NaN             NaN   \n",
      "3  1.042869e+07 -7.577123e+06              NaN            NaN             NaN   \n",
      "4  1.042869e+07 -7.577123e+06              NaN            NaN             NaN   \n",
      "\n",
      "    ds  accept_hour  accept_minute  \n",
      "0  319            7             25  \n",
      "1  319            7             55  \n",
      "2  319           13             11  \n",
      "3  319           10             14  \n",
      "4  319            8             11  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "# Data preprocessing for pickup\n",
    "def preprocess_pickup_data(df):\n",
    "    \"\"\"Preprocess pickup data\"\"\"\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    # Convert time columns\n",
    "    for col in ['accept_time', 'book_start_time', 'expect_got_time', 'got_time']:\n",
    "        if col in df_copy.columns:\n",
    "            df_copy[col] = pd.to_datetime(df_copy[col], format='%m-%d %H:%M:%S', errors='coerce')\n",
    "    \n",
    "    # Extract features from timestamps\n",
    "    if 'accept_time' in df_copy.columns:\n",
    "        df_copy['accept_hour'] = df_copy['accept_time'].dt.hour\n",
    "        df_copy['accept_minute'] = df_copy['accept_time'].dt.minute\n",
    "    \n",
    "    # Handle geographic coordinates\n",
    "    df_copy['poi_lng'] = pd.to_numeric(df_copy['poi_lng'], errors='coerce')\n",
    "    df_copy['poi_lat'] = pd.to_numeric(df_copy['poi_lat'], errors='coerce')\n",
    "    \n",
    "    # Fill missing values\n",
    "    numeric_cols = df_copy.select_dtypes(include=[np.number]).columns\n",
    "    df_copy[numeric_cols] = df_copy[numeric_cols].fillna(df_copy[numeric_cols].median())\n",
    "    \n",
    "    return df_copy\n",
    "\n",
    "def preprocess_delivery_data(df):\n",
    "    \"\"\"Preprocess delivery data\"\"\"\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    # Convert time columns\n",
    "    for col in ['receipt_time', 'sign_time']:\n",
    "        if col in df_copy.columns:\n",
    "            df_copy[col] = pd.to_datetime(df_copy[col], format='%m-%d %H:%M:%S', errors='coerce')\n",
    "    \n",
    "    # Extract features from timestamps\n",
    "    if 'receipt_time' in df_copy.columns:\n",
    "        df_copy['receipt_hour'] = df_copy['receipt_time'].dt.hour\n",
    "        df_copy['receipt_minute'] = df_copy['receipt_time'].dt.minute\n",
    "    \n",
    "    # Handle geographic coordinates\n",
    "    df_copy['poi_lng'] = pd.to_numeric(df_copy['poi_lng'], errors='coerce')\n",
    "    df_copy['poi_lat'] = pd.to_numeric(df_copy['poi_lat'], errors='coerce')\n",
    "    \n",
    "    # Fill missing values\n",
    "    numeric_cols = df_copy.select_dtypes(include=[np.number]).columns\n",
    "    df_copy[numeric_cols] = df_copy[numeric_cols].fillna(df_copy[numeric_cols].median())\n",
    "    \n",
    "    return df_copy\n",
    "\n",
    "print(\"Preprocessing data...\")\n",
    "pickup_processed = preprocess_pickup_data(pickup_df)\n",
    "delivery_processed = preprocess_delivery_data(delivery_df)\n",
    "\n",
    "print(f\"Processed pickup data shape: {pickup_processed.shape}\")\n",
    "print(f\"Processed delivery data shape: {delivery_processed.shape}\")\n",
    "print(\"\\nProcessed pickup sample:\")\n",
    "print(pickup_processed.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0a947fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating efficiency metrics...\n",
      "Efficiency score range (pickup): 0.0000 - 1.0000\n",
      "Efficiency score range (delivery): 0.0000 - 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Calculate delivery efficiency as target variable\n",
    "def calculate_efficiency_metrics(pickup_df, delivery_df):\n",
    "    \"\"\"Calculate efficiency metrics from pickup and delivery data\"\"\"\n",
    "    \n",
    "    # Distance calculation using Haversine formula approximation\n",
    "    pickup_df['distance'] = np.sqrt(\n",
    "        (pickup_df['poi_lng'] - pickup_df['poi_lng'].mean())**2 + \n",
    "        (pickup_df['poi_lat'] - pickup_df['poi_lat'].mean())**2\n",
    "    )\n",
    "    \n",
    "    delivery_df['distance'] = np.sqrt(\n",
    "        (delivery_df['poi_lng'] - delivery_df['poi_lng'].mean())**2 + \n",
    "        (delivery_df['poi_lat'] - delivery_df['poi_lat'].mean())**2\n",
    "    )\n",
    "    \n",
    "    # Normalize distances\n",
    "    pickup_df['distance_normalized'] = (pickup_df['distance'] - pickup_df['distance'].min()) / (pickup_df['distance'].max() - pickup_df['distance'].min() + 1e-8)\n",
    "    delivery_df['distance_normalized'] = (delivery_df['distance'] - delivery_df['distance'].min()) / (delivery_df['distance'].max() - delivery_df['distance'].min() + 1e-8)\n",
    "    \n",
    "    # Efficiency score (lower is better - normalized distance)\n",
    "    pickup_df['efficiency_score'] = pickup_df['distance_normalized']\n",
    "    delivery_df['efficiency_score'] = delivery_df['distance_normalized']\n",
    "    \n",
    "    return pickup_df, delivery_df\n",
    "\n",
    "print(\"Calculating efficiency metrics...\")\n",
    "pickup_processed, delivery_processed = calculate_efficiency_metrics(pickup_processed, delivery_processed)\n",
    "\n",
    "print(f\"Efficiency score range (pickup): {pickup_processed['efficiency_score'].min():.4f} - {pickup_processed['efficiency_score'].max():.4f}\")\n",
    "print(f\"Efficiency score range (delivery): {delivery_processed['efficiency_score'].min():.4f} - {delivery_processed['efficiency_score'].max():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f20f1fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickup features: ['poi_lng', 'poi_lat', 'distance_normalized', 'accept_hour', 'accept_minute', 'from_city_name']\n",
      "Delivery features: ['poi_lng', 'poi_lat', 'distance_normalized', 'receipt_hour', 'receipt_minute', 'from_city_name']\n"
     ]
    }
   ],
   "source": [
    "# Prepare features for deep learning model\n",
    "def prepare_features_for_model(df, type_='pickup'):\n",
    "    \"\"\"Prepare features for neural network\"\"\"\n",
    "    features = []\n",
    "    \n",
    "    # Numeric features\n",
    "    if type_ == 'pickup':\n",
    "        time_features = ['accept_hour', 'accept_minute'] if 'accept_hour' in df.columns else []\n",
    "    else:\n",
    "        time_features = ['receipt_hour', 'receipt_minute'] if 'receipt_hour' in df.columns else []\n",
    "    \n",
    "    numeric_features = ['poi_lng', 'poi_lat', 'distance_normalized'] + time_features\n",
    "    numeric_features = [f for f in numeric_features if f in df.columns]\n",
    "    \n",
    "    # Categorical features\n",
    "    categorical_features = ['from_city_name'] if 'from_city_name' in df.columns else []\n",
    "    \n",
    "    features = numeric_features + categorical_features\n",
    "    return features\n",
    "\n",
    "pickup_features = prepare_features_for_model(pickup_processed, 'pickup')\n",
    "delivery_features = prepare_features_for_model(delivery_processed, 'delivery')\n",
    "\n",
    "print(f\"Pickup features: {pickup_features}\")\n",
    "print(f\"Delivery features: {delivery_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a41b0a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing training data...\n",
      "Pickup training data: X_train (424892, 6), y_train (424892,)\n",
      "Delivery training data: X_train (377935, 6), y_train (377935,)\n",
      "Pickup training data: X_train (424892, 6), y_train (424892,)\n",
      "Delivery training data: X_train (377935, 6), y_train (377935,)\n"
     ]
    }
   ],
   "source": [
    "# Encode categorical features and prepare training data\n",
    "def prepare_training_data(df, features, test_size=0.2):\n",
    "    \"\"\"Prepare training and testing datasets\"\"\"\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    # Encode categorical variables\n",
    "    categorical_cols = [f for f in features if df_copy[f].dtype == 'category' or df_copy[f].dtype == 'object']\n",
    "    encoders = {}\n",
    "    \n",
    "    for col in categorical_cols:\n",
    "        le = LabelEncoder()\n",
    "        df_copy[col] = le.fit_transform(df_copy[col].astype(str))\n",
    "        encoders[col] = le\n",
    "    \n",
    "    # Prepare X and y\n",
    "    X = df_copy[features].values.astype(np.float32)\n",
    "    y = df_copy['efficiency_score'].values.astype(np.float32)\n",
    "    \n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_scaled, y, test_size=test_size, random_state=42\n",
    "    )\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, scaler, encoders\n",
    "\n",
    "print(\"Preparing training data...\")\n",
    "X_train_pickup, X_test_pickup, y_train_pickup, y_test_pickup, scaler_pickup, encoders_pickup = prepare_training_data(\n",
    "    pickup_processed, pickup_features\n",
    ")\n",
    "\n",
    "X_train_delivery, X_test_delivery, y_train_delivery, y_test_delivery, scaler_delivery, encoders_delivery = prepare_training_data(\n",
    "    delivery_processed, delivery_features\n",
    ")\n",
    "\n",
    "print(f\"Pickup training data: X_train {X_train_pickup.shape}, y_train {y_train_pickup.shape}\")\n",
    "print(f\"Delivery training data: X_train {X_train_delivery.shape}, y_train {y_train_delivery.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd8e0209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building deep learning models...\n",
      "\n",
      "Pickup Model:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"pickup_optimizer\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"pickup_optimizer\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ pickup_optimizer_input          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ pickup_optimizer_dense_1        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                         │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ pickup_optimizer_dense_2        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                         │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ pickup_optimizer_dense_3        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                         │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ pickup_optimizer_dense_4        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                         │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ pickup_optimizer_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ pickup_optimizer_input          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ pickup_optimizer_dense_1        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m896\u001b[0m │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)                         │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ pickup_optimizer_dense_2        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)                         │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ pickup_optimizer_dense_3        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)                         │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ pickup_optimizer_dense_4        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m528\u001b[0m │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)                         │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ pickup_optimizer_output (\u001b[38;5;33mDense\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m17\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,673</span> (49.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m12,673\u001b[0m (49.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,225</span> (47.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,225\u001b[0m (47.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Delivery Model:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"delivery_optimizer\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"delivery_optimizer\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ delivery_optimizer_input        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ delivery_optimizer_dense_1      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                         │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ delivery_optimizer_dense_2      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                         │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ delivery_optimizer_dense_3      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                         │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ delivery_optimizer_dense_4      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                         │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ delivery_optimizer_output       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                         │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ delivery_optimizer_input        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)                    │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ delivery_optimizer_dense_1      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m896\u001b[0m │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)                         │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ delivery_optimizer_dense_2      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)                         │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ delivery_optimizer_dense_3      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)                         │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ delivery_optimizer_dense_4      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m528\u001b[0m │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)                         │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ delivery_optimizer_output       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m17\u001b[0m │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)                         │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,673</span> (49.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m12,673\u001b[0m (49.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,225</span> (47.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,225\u001b[0m (47.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build deep neural network model\n",
    "def build_deep_learning_model(input_dim, model_name='route_optimizer'):\n",
    "    \"\"\"Build a deep neural network for route optimization\"\"\"\n",
    "    \n",
    "    inputs = layers.Input(shape=(input_dim,), name=f'{model_name}_input')\n",
    "    \n",
    "    # First dense block\n",
    "    x = layers.Dense(128, activation='relu', name=f'{model_name}_dense_1')(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    \n",
    "    # Second dense block\n",
    "    x = layers.Dense(64, activation='relu', name=f'{model_name}_dense_2')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    \n",
    "    # Third dense block\n",
    "    x = layers.Dense(32, activation='relu', name=f'{model_name}_dense_3')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    \n",
    "    # Fourth dense block\n",
    "    x = layers.Dense(16, activation='relu', name=f'{model_name}_dense_4')(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    \n",
    "    # Output layer\n",
    "    outputs = layers.Dense(1, activation='sigmoid', name=f'{model_name}_output')(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs, name=model_name)\n",
    "    return model\n",
    "\n",
    "print(\"Building deep learning models...\")\n",
    "pickup_model = build_deep_learning_model(X_train_pickup.shape[1], 'pickup_optimizer')\n",
    "delivery_model = build_deep_learning_model(X_train_delivery.shape[1], 'delivery_optimizer')\n",
    "\n",
    "# Compile models\n",
    "pickup_model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='mse',\n",
    "    metrics=['mae', 'mse']\n",
    ")\n",
    "\n",
    "delivery_model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='mse',\n",
    "    metrics=['mae', 'mse']\n",
    ")\n",
    "\n",
    "print(\"\\nPickup Model:\")\n",
    "pickup_model.summary()\n",
    "\n",
    "print(\"\\nDelivery Model:\")\n",
    "delivery_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5925416b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training pickup model...\n",
      "Epoch 1/20\n",
      "Epoch 1/20\n",
      "\u001b[1m10623/10623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - loss: 0.0030 - mae: 0.0355 - mse: 0.0030 - val_loss: 4.1958e-04 - val_mae: 0.0174 - val_mse: 4.1958e-04 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m10623/10623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - loss: 0.0030 - mae: 0.0355 - mse: 0.0030 - val_loss: 4.1958e-04 - val_mae: 0.0174 - val_mse: 4.1958e-04 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m10623/10623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2ms/step - loss: 0.0012 - mae: 0.0255 - mse: 0.0012 - val_loss: 3.5802e-04 - val_mae: 0.0154 - val_mse: 3.5802e-04 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m10623/10623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2ms/step - loss: 0.0012 - mae: 0.0255 - mse: 0.0012 - val_loss: 3.5802e-04 - val_mae: 0.0154 - val_mse: 3.5802e-04 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m10623/10623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2ms/step - loss: 0.0011 - mae: 0.0245 - mse: 0.0011 - val_loss: 3.9299e-04 - val_mae: 0.0174 - val_mse: 3.9299e-04 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m10623/10623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2ms/step - loss: 0.0011 - mae: 0.0245 - mse: 0.0011 - val_loss: 3.9299e-04 - val_mae: 0.0174 - val_mse: 3.9299e-04 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m10623/10623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2ms/step - loss: 0.0010 - mae: 0.0239 - mse: 0.0010 - val_loss: 2.4167e-04 - val_mae: 0.0131 - val_mse: 2.4167e-04 - learning_rate: 5.0000e-04\n",
      "Epoch 5/20\n",
      "\u001b[1m10623/10623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2ms/step - loss: 0.0010 - mae: 0.0239 - mse: 0.0010 - val_loss: 2.4167e-04 - val_mae: 0.0131 - val_mse: 2.4167e-04 - learning_rate: 5.0000e-04\n",
      "Epoch 5/20\n",
      "\u001b[1m10623/10623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2ms/step - loss: 9.7140e-04 - mae: 0.0234 - mse: 9.7140e-04 - val_loss: 1.8071e-04 - val_mae: 0.0112 - val_mse: 1.8071e-04 - learning_rate: 5.0000e-04\n",
      "Epoch 6/20\n",
      "\u001b[1m10623/10623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2ms/step - loss: 9.7140e-04 - mae: 0.0234 - mse: 9.7140e-04 - val_loss: 1.8071e-04 - val_mae: 0.0112 - val_mse: 1.8071e-04 - learning_rate: 5.0000e-04\n",
      "Epoch 6/20\n",
      "\u001b[1m10623/10623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2ms/step - loss: 9.5022e-04 - mae: 0.0231 - mse: 9.5022e-04 - val_loss: 2.0991e-04 - val_mae: 0.0120 - val_mse: 2.0991e-04 - learning_rate: 5.0000e-04\n",
      "Epoch 7/20\n",
      "\u001b[1m10623/10623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2ms/step - loss: 9.5022e-04 - mae: 0.0231 - mse: 9.5022e-04 - val_loss: 2.0991e-04 - val_mae: 0.0120 - val_mse: 2.0991e-04 - learning_rate: 5.0000e-04\n",
      "Epoch 7/20\n",
      "\u001b[1m10623/10623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2ms/step - loss: 9.3893e-04 - mae: 0.0230 - mse: 9.3893e-04 - val_loss: 1.9006e-04 - val_mae: 0.0118 - val_mse: 1.9006e-04 - learning_rate: 2.5000e-04\n",
      "Epoch 8/20\n",
      "\u001b[1m10623/10623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2ms/step - loss: 9.3893e-04 - mae: 0.0230 - mse: 9.3893e-04 - val_loss: 1.9006e-04 - val_mae: 0.0118 - val_mse: 1.9006e-04 - learning_rate: 2.5000e-04\n",
      "Epoch 8/20\n",
      "\u001b[1m10623/10623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - loss: 9.2559e-04 - mae: 0.0228 - mse: 9.2559e-04 - val_loss: 1.7394e-04 - val_mae: 0.0112 - val_mse: 1.7394e-04 - learning_rate: 2.5000e-04\n",
      "Epoch 9/20\n",
      "\u001b[1m10623/10623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - loss: 9.2559e-04 - mae: 0.0228 - mse: 9.2559e-04 - val_loss: 1.7394e-04 - val_mae: 0.0112 - val_mse: 1.7394e-04 - learning_rate: 2.5000e-04\n",
      "Epoch 9/20\n",
      "\u001b[1m10623/10623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - loss: 9.1967e-04 - mae: 0.0228 - mse: 9.1967e-04 - val_loss: 2.0563e-04 - val_mae: 0.0127 - val_mse: 2.0563e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m10623/10623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - loss: 9.1967e-04 - mae: 0.0228 - mse: 9.1967e-04 - val_loss: 2.0563e-04 - val_mae: 0.0127 - val_mse: 2.0563e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m10623/10623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - loss: 9.1303e-04 - mae: 0.0227 - mse: 9.1303e-04 - val_loss: 1.9709e-04 - val_mae: 0.0124 - val_mse: 1.9709e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m10623/10623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - loss: 9.1303e-04 - mae: 0.0227 - mse: 9.1303e-04 - val_loss: 1.9709e-04 - val_mae: 0.0124 - val_mse: 1.9709e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m10623/10623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step - loss: 9.1926e-04 - mae: 0.0227 - mse: 9.1926e-04 - val_loss: 1.7815e-04 - val_mae: 0.0118 - val_mse: 1.7815e-04 - learning_rate: 6.2500e-05\n",
      "\u001b[1m10623/10623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step - loss: 9.1926e-04 - mae: 0.0227 - mse: 9.1926e-04 - val_loss: 1.7815e-04 - val_mae: 0.0118 - val_mse: 1.7815e-04 - learning_rate: 6.2500e-05\n",
      "\n",
      "Training delivery model...\n",
      "Epoch 1/20\n",
      "\n",
      "Training delivery model...\n",
      "Epoch 1/20\n",
      "\u001b[1m9449/9449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step - loss: 0.0030 - mae: 0.0377 - mse: 0.0030 - val_loss: 5.0658e-04 - val_mae: 0.0157 - val_mse: 5.0658e-04 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m9449/9449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step - loss: 0.0030 - mae: 0.0377 - mse: 0.0030 - val_loss: 5.0658e-04 - val_mae: 0.0157 - val_mse: 5.0658e-04 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m9449/9449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - loss: 0.0018 - mae: 0.0282 - mse: 0.0018 - val_loss: 4.2844e-04 - val_mae: 0.0118 - val_mse: 4.2844e-04 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m9449/9449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2ms/step - loss: 0.0018 - mae: 0.0282 - mse: 0.0018 - val_loss: 4.2844e-04 - val_mae: 0.0118 - val_mse: 4.2844e-04 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m9449/9449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - loss: 0.0016 - mae: 0.0268 - mse: 0.0016 - val_loss: 2.1822e-04 - val_mae: 0.0095 - val_mse: 2.1822e-04 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m9449/9449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - loss: 0.0016 - mae: 0.0268 - mse: 0.0016 - val_loss: 2.1822e-04 - val_mae: 0.0095 - val_mse: 2.1822e-04 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m9449/9449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step - loss: 0.0015 - mae: 0.0260 - mse: 0.0015 - val_loss: 4.6913e-04 - val_mae: 0.0126 - val_mse: 4.6913e-04 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m9449/9449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step - loss: 0.0015 - mae: 0.0260 - mse: 0.0015 - val_loss: 4.6913e-04 - val_mae: 0.0126 - val_mse: 4.6913e-04 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m9449/9449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - loss: 0.0015 - mae: 0.0256 - mse: 0.0015 - val_loss: 2.1754e-04 - val_mae: 0.0105 - val_mse: 2.1754e-04 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m9449/9449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2ms/step - loss: 0.0015 - mae: 0.0256 - mse: 0.0015 - val_loss: 2.1754e-04 - val_mae: 0.0105 - val_mse: 2.1754e-04 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m9449/9449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step - loss: 0.0015 - mae: 0.0251 - mse: 0.0015 - val_loss: 2.0260e-04 - val_mae: 0.0088 - val_mse: 2.0260e-04 - learning_rate: 5.0000e-04\n",
      "Epoch 7/20\n",
      "\u001b[1m9449/9449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step - loss: 0.0015 - mae: 0.0251 - mse: 0.0015 - val_loss: 2.0260e-04 - val_mae: 0.0088 - val_mse: 2.0260e-04 - learning_rate: 5.0000e-04\n",
      "Epoch 7/20\n",
      "\u001b[1m9449/9449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step - loss: 0.0015 - mae: 0.0249 - mse: 0.0015 - val_loss: 1.6231e-04 - val_mae: 0.0077 - val_mse: 1.6231e-04 - learning_rate: 5.0000e-04\n",
      "Epoch 8/20\n",
      "\u001b[1m9449/9449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step - loss: 0.0015 - mae: 0.0249 - mse: 0.0015 - val_loss: 1.6231e-04 - val_mae: 0.0077 - val_mse: 1.6231e-04 - learning_rate: 5.0000e-04\n",
      "Epoch 8/20\n",
      "\u001b[1m9449/9449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step - loss: 0.0014 - mae: 0.0247 - mse: 0.0014 - val_loss: 2.6331e-04 - val_mae: 0.0099 - val_mse: 2.6331e-04 - learning_rate: 2.5000e-04\n",
      "Epoch 9/20\n",
      "\u001b[1m9449/9449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step - loss: 0.0014 - mae: 0.0247 - mse: 0.0014 - val_loss: 2.6331e-04 - val_mae: 0.0099 - val_mse: 2.6331e-04 - learning_rate: 2.5000e-04\n",
      "Epoch 9/20\n",
      "\u001b[1m9449/9449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step - loss: 0.0014 - mae: 0.0247 - mse: 0.0014 - val_loss: 1.8773e-04 - val_mae: 0.0090 - val_mse: 1.8773e-04 - learning_rate: 2.5000e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m9449/9449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2ms/step - loss: 0.0014 - mae: 0.0247 - mse: 0.0014 - val_loss: 1.8773e-04 - val_mae: 0.0090 - val_mse: 1.8773e-04 - learning_rate: 2.5000e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m9449/9449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - loss: 0.0014 - mae: 0.0246 - mse: 0.0014 - val_loss: 1.7445e-04 - val_mae: 0.0081 - val_mse: 1.7445e-04 - learning_rate: 1.2500e-04\n",
      "\u001b[1m9449/9449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - loss: 0.0014 - mae: 0.0246 - mse: 0.0014 - val_loss: 1.7445e-04 - val_mae: 0.0081 - val_mse: 1.7445e-04 - learning_rate: 1.2500e-04\n"
     ]
    }
   ],
   "source": [
    "# Train models\n",
    "print(\"Training pickup model...\")\n",
    "history_pickup = pickup_model.fit(\n",
    "    X_train_pickup, y_train_pickup,\n",
    "    batch_size=32,\n",
    "    epochs=20,\n",
    "    validation_split=0.2,\n",
    "    verbose=1,\n",
    "    callbacks=[\n",
    "        keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True),\n",
    "        keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-6)\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"\\nTraining delivery model...\")\n",
    "history_delivery = delivery_model.fit(\n",
    "    X_train_delivery, y_train_delivery,\n",
    "    batch_size=32,\n",
    "    epochs=20,\n",
    "    validation_split=0.2,\n",
    "    verbose=1,\n",
    "    callbacks=[\n",
    "        keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True),\n",
    "        keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-6)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e397a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating models...\n",
      "\n",
      "Pickup Model Test Results:\n",
      "  Loss (MSE): 0.000174\n",
      "  MAE: 0.011246\n",
      "  MSE: 0.000174\n",
      "\n",
      "Pickup Model Test Results:\n",
      "  Loss (MSE): 0.000174\n",
      "  MAE: 0.011246\n",
      "  MSE: 0.000174\n",
      "\n",
      "Delivery Model Test Results:\n",
      "  Loss (MSE): 0.000163\n",
      "  MAE: 0.007679\n",
      "  MSE: 0.000163\n",
      "\u001b[1m   1/3320\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:19\u001b[0m 60ms/step\n",
      "Delivery Model Test Results:\n",
      "  Loss (MSE): 0.000163\n",
      "  MAE: 0.007679\n",
      "  MSE: 0.000163\n",
      "\u001b[1m3320/3320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 457us/step\n",
      "\u001b[1m3320/3320\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 457us/step\n",
      "\u001b[1m2953/2953\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 543us/step\n",
      "\u001b[1m2953/2953\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 543us/step\n",
      "\n",
      "Pickup predictions shape: (106223, 1)\n",
      "Delivery predictions shape: (94484, 1)\n",
      "\n",
      "Pickup predictions shape: (106223, 1)\n",
      "Delivery predictions shape: (94484, 1)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate models\n",
    "print(\"Evaluating models...\")\n",
    "\n",
    "# Pickup evaluation\n",
    "pickup_test_loss, pickup_test_mae, pickup_test_mse = pickup_model.evaluate(X_test_pickup, y_test_pickup, verbose=0)\n",
    "print(f\"\\nPickup Model Test Results:\")\n",
    "print(f\"  Loss (MSE): {pickup_test_loss:.6f}\")\n",
    "print(f\"  MAE: {pickup_test_mae:.6f}\")\n",
    "print(f\"  MSE: {pickup_test_mse:.6f}\")\n",
    "\n",
    "# Delivery evaluation\n",
    "delivery_test_loss, delivery_test_mae, delivery_test_mse = delivery_model.evaluate(X_test_delivery, y_test_delivery, verbose=0)\n",
    "print(f\"\\nDelivery Model Test Results:\")\n",
    "print(f\"  Loss (MSE): {delivery_test_loss:.6f}\")\n",
    "print(f\"  MAE: {delivery_test_mae:.6f}\")\n",
    "print(f\"  MSE: {delivery_test_mse:.6f}\")\n",
    "\n",
    "# Make predictions\n",
    "y_pred_pickup = pickup_model.predict(X_test_pickup)\n",
    "y_pred_delivery = delivery_model.predict(X_test_delivery)\n",
    "\n",
    "print(f\"\\nPickup predictions shape: {y_pred_pickup.shape}\")\n",
    "print(f\"Delivery predictions shape: {y_pred_delivery.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "406b3b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating route optimization recommendations...\n",
      "\n",
      "Pickup Recommendations Summary:\n",
      "action\n",
      "Optimize    52913\n",
      "Maintain    45391\n",
      "Review       7919\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Delivery Recommendations Summary:\n",
      "action\n",
      "Maintain    49389\n",
      "Optimize    32612\n",
      "Review      12483\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Pickup Sample Recommendations:\n",
      "     action priority  current_efficiency  predicted_efficiency  \\\n",
      "0  Maintain      Low            0.022024              0.076469   \n",
      "1  Optimize     High            0.015605              0.006637   \n",
      "2  Optimize     High            0.277097              0.060153   \n",
      "3  Maintain      Low            0.024134              0.333979   \n",
      "4  Maintain      Low            0.064055              0.304847   \n",
      "5  Maintain      Low            0.018414              0.342364   \n",
      "6  Optimize     High            0.023506              0.005243   \n",
      "7  Maintain      Low            0.318400              0.560758   \n",
      "8  Optimize     High            0.477149              0.033445   \n",
      "9  Maintain      Low            0.513204              0.556994   \n",
      "\n",
      "   improvement_potential  \n",
      "0              -0.054445  \n",
      "1               0.008968  \n",
      "2               0.216944  \n",
      "3              -0.309845  \n",
      "4              -0.240792  \n",
      "5              -0.323949  \n",
      "6               0.018263  \n",
      "7              -0.242358  \n",
      "8               0.443705  \n",
      "9              -0.043790  \n",
      "\n",
      "Delivery Sample Recommendations:\n",
      "     action priority  current_efficiency  predicted_efficiency  \\\n",
      "0    Review   Medium            0.264969              0.264586   \n",
      "1  Optimize     High            0.907478              0.717835   \n",
      "2  Optimize     High            0.278970              0.139514   \n",
      "3  Maintain      Low            0.264604              0.266716   \n",
      "4  Maintain      Low            0.146904              0.252563   \n",
      "5  Maintain      Low            0.260436              0.268199   \n",
      "6  Optimize     High            0.898798              0.265342   \n",
      "7  Maintain      Low            0.109083              0.287400   \n",
      "8  Maintain      Low            0.889560              0.917713   \n",
      "9  Optimize     High            0.898229              0.139316   \n",
      "\n",
      "   improvement_potential  \n",
      "0               0.000382  \n",
      "1               0.189643  \n",
      "2               0.139455  \n",
      "3              -0.002112  \n",
      "4              -0.105659  \n",
      "5              -0.007763  \n",
      "6               0.633455  \n",
      "7              -0.178317  \n",
      "8              -0.028153  \n",
      "9               0.758913  \n",
      "\n",
      "Pickup Recommendations Summary:\n",
      "action\n",
      "Optimize    52913\n",
      "Maintain    45391\n",
      "Review       7919\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Delivery Recommendations Summary:\n",
      "action\n",
      "Maintain    49389\n",
      "Optimize    32612\n",
      "Review      12483\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Pickup Sample Recommendations:\n",
      "     action priority  current_efficiency  predicted_efficiency  \\\n",
      "0  Maintain      Low            0.022024              0.076469   \n",
      "1  Optimize     High            0.015605              0.006637   \n",
      "2  Optimize     High            0.277097              0.060153   \n",
      "3  Maintain      Low            0.024134              0.333979   \n",
      "4  Maintain      Low            0.064055              0.304847   \n",
      "5  Maintain      Low            0.018414              0.342364   \n",
      "6  Optimize     High            0.023506              0.005243   \n",
      "7  Maintain      Low            0.318400              0.560758   \n",
      "8  Optimize     High            0.477149              0.033445   \n",
      "9  Maintain      Low            0.513204              0.556994   \n",
      "\n",
      "   improvement_potential  \n",
      "0              -0.054445  \n",
      "1               0.008968  \n",
      "2               0.216944  \n",
      "3              -0.309845  \n",
      "4              -0.240792  \n",
      "5              -0.323949  \n",
      "6               0.018263  \n",
      "7              -0.242358  \n",
      "8               0.443705  \n",
      "9              -0.043790  \n",
      "\n",
      "Delivery Sample Recommendations:\n",
      "     action priority  current_efficiency  predicted_efficiency  \\\n",
      "0    Review   Medium            0.264969              0.264586   \n",
      "1  Optimize     High            0.907478              0.717835   \n",
      "2  Optimize     High            0.278970              0.139514   \n",
      "3  Maintain      Low            0.264604              0.266716   \n",
      "4  Maintain      Low            0.146904              0.252563   \n",
      "5  Maintain      Low            0.260436              0.268199   \n",
      "6  Optimize     High            0.898798              0.265342   \n",
      "7  Maintain      Low            0.109083              0.287400   \n",
      "8  Maintain      Low            0.889560              0.917713   \n",
      "9  Optimize     High            0.898229              0.139316   \n",
      "\n",
      "   improvement_potential  \n",
      "0               0.000382  \n",
      "1               0.189643  \n",
      "2               0.139455  \n",
      "3              -0.002112  \n",
      "4              -0.105659  \n",
      "5              -0.007763  \n",
      "6               0.633455  \n",
      "7              -0.178317  \n",
      "8              -0.028153  \n",
      "9               0.758913  \n"
     ]
    }
   ],
   "source": [
    "# Generate route optimization recommendations\n",
    "def generate_route_recommendations(df, predictions, original_data):\n",
    "    \"\"\"Generate route optimization recommendations based on predictions\"\"\"\n",
    "    recommendations = []\n",
    "    \n",
    "    for idx, (pred, score) in enumerate(zip(predictions, original_data['efficiency_score'].values)):\n",
    "        pred_score = pred[0]\n",
    "        \n",
    "        if pred_score < score * 0.8:  # Significant improvement possible\n",
    "            action = 'Optimize'\n",
    "            priority = 'High'\n",
    "        elif pred_score < score:\n",
    "            action = 'Review'\n",
    "            priority = 'Medium'\n",
    "        else:\n",
    "            action = 'Maintain'\n",
    "            priority = 'Low'\n",
    "        \n",
    "        recommendations.append({\n",
    "            'action': action,\n",
    "            'priority': priority,\n",
    "            'current_efficiency': float(score),\n",
    "            'predicted_efficiency': float(pred_score),\n",
    "            'improvement_potential': float(score - pred_score)\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(recommendations)\n",
    "\n",
    "print(\"Generating route optimization recommendations...\")\n",
    "pickup_recommendations = generate_route_recommendations(pickup_processed, y_pred_pickup, pickup_processed)\n",
    "delivery_recommendations = generate_route_recommendations(delivery_processed, y_pred_delivery, delivery_processed)\n",
    "\n",
    "print(f\"\\nPickup Recommendations Summary:\")\n",
    "print(pickup_recommendations['action'].value_counts())\n",
    "print(f\"\\nDelivery Recommendations Summary:\")\n",
    "print(delivery_recommendations['action'].value_counts())\n",
    "\n",
    "print(f\"\\nPickup Sample Recommendations:\")\n",
    "print(pickup_recommendations.head(10))\n",
    "\n",
    "print(f\"\\nDelivery Sample Recommendations:\")\n",
    "print(delivery_recommendations.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6096d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving models and artifacts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickup model saved: /home/sirin/BIGDATA/quick-result/pickup_optimizer_model_20251120_163355.h5\n",
      "Delivery model saved: /home/sirin/BIGDATA/quick-result/delivery_optimizer_model_20251120_163355.h5\n",
      "Preprocessing artifacts saved: /home/sirin/BIGDATA/quick-result/preprocessing_artifacts_20251120_163355.pkl\n"
     ]
    }
   ],
   "source": [
    "# Save models and artifacts\n",
    "print(\"Saving models and artifacts...\")\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "# Save TensorFlow models\n",
    "pickup_model_path = os.path.join(OUTPUT_PATH, f'pickup_optimizer_model_{timestamp}.h5')\n",
    "delivery_model_path = os.path.join(OUTPUT_PATH, f'delivery_optimizer_model_{timestamp}.h5')\n",
    "\n",
    "pickup_model.save(pickup_model_path)\n",
    "delivery_model.save(delivery_model_path)\n",
    "\n",
    "print(f\"Pickup model saved: {pickup_model_path}\")\n",
    "print(f\"Delivery model saved: {delivery_model_path}\")\n",
    "\n",
    "# Save scalers and encoders\n",
    "scaler_artifacts = {\n",
    "    'pickup_scaler': scaler_pickup,\n",
    "    'delivery_scaler': scaler_delivery,\n",
    "    'pickup_encoders': encoders_pickup,\n",
    "    'delivery_encoders': encoders_delivery\n",
    "}\n",
    "\n",
    "artifacts_path = os.path.join(OUTPUT_PATH, f'preprocessing_artifacts_{timestamp}.pkl')\n",
    "joblib.dump(scaler_artifacts, artifacts_path)\n",
    "print(f\"Preprocessing artifacts saved: {artifacts_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "baa028da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting results to CSV...\n",
      "Pickup results exported: /home/sirin/BIGDATA/quick-result/pickup_optimization_results_20251120_163355.csv\n",
      "Pickup results exported: /home/sirin/BIGDATA/quick-result/pickup_optimization_results_20251120_163355.csv\n",
      "Delivery results exported: /home/sirin/BIGDATA/quick-result/delivery_optimization_results_20251120_163355.csv\n",
      "Delivery results exported: /home/sirin/BIGDATA/quick-result/delivery_optimization_results_20251120_163355.csv\n"
     ]
    }
   ],
   "source": [
    "# Export results to CSV\n",
    "print(\"Exporting results to CSV...\")\n",
    "\n",
    "# Pickup results\n",
    "pickup_results = pickup_processed[['order_id', 'from_city_name', 'poi_lng', 'poi_lat', 'efficiency_score']].copy()\n",
    "pickup_results_with_pred = pickup_results.iloc[len(pickup_results) - len(y_pred_pickup):].copy()\n",
    "pickup_results_with_pred['predicted_efficiency'] = y_pred_pickup.flatten()\n",
    "pickup_results_with_pred = pickup_results_with_pred.reset_index(drop=True)\n",
    "pickup_results_with_pred['action'] = pickup_recommendations['action'].values[:len(pickup_results_with_pred)]\n",
    "pickup_results_with_pred['priority'] = pickup_recommendations['priority'].values[:len(pickup_results_with_pred)]\n",
    "pickup_results_with_pred['improvement_potential'] = pickup_recommendations['improvement_potential'].values[:len(pickup_results_with_pred)]\n",
    "\n",
    "pickup_export = os.path.join(OUTPUT_PATH, f'pickup_optimization_results_{timestamp}.csv')\n",
    "pickup_results_with_pred.to_csv(pickup_export, index=False)\n",
    "print(f\"Pickup results exported: {pickup_export}\")\n",
    "\n",
    "# Delivery results\n",
    "delivery_results = delivery_processed[['order_id', 'from_city_name', 'poi_lng', 'poi_lat', 'efficiency_score']].copy()\n",
    "delivery_results_with_pred = delivery_results.iloc[len(delivery_results) - len(y_pred_delivery):].copy()\n",
    "delivery_results_with_pred['predicted_efficiency'] = y_pred_delivery.flatten()\n",
    "delivery_results_with_pred = delivery_results_with_pred.reset_index(drop=True)\n",
    "delivery_results_with_pred['action'] = delivery_recommendations['action'].values[:len(delivery_results_with_pred)]\n",
    "delivery_results_with_pred['priority'] = delivery_recommendations['priority'].values[:len(delivery_results_with_pred)]\n",
    "delivery_results_with_pred['improvement_potential'] = delivery_recommendations['improvement_potential'].values[:len(delivery_results_with_pred)]\n",
    "\n",
    "delivery_export = os.path.join(OUTPUT_PATH, f'delivery_optimization_results_{timestamp}.csv')\n",
    "delivery_results_with_pred.to_csv(delivery_export, index=False)\n",
    "print(f\"Delivery results exported: {delivery_export}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d7b18d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting recommendations summary...\n",
      "Recommendations summary exported: /home/sirin/BIGDATA/quick-result/recommendations_summary_20251120_163355.csv\n",
      "Recommendations summary exported: /home/sirin/BIGDATA/quick-result/recommendations_summary_20251120_163355.csv\n"
     ]
    }
   ],
   "source": [
    "# Export recommendations summary\n",
    "print(\"Exporting recommendations summary...\")\n",
    "\n",
    "recommendations_summary = os.path.join(OUTPUT_PATH, f'recommendations_summary_{timestamp}.csv')\n",
    "combined_recommendations = pd.concat([\n",
    "    pickup_recommendations.assign(type='pickup'),\n",
    "    delivery_recommendations.assign(type='delivery')\n",
    "], ignore_index=True)\n",
    "\n",
    "combined_recommendations.to_csv(recommendations_summary, index=False)\n",
    "print(f\"Recommendations summary exported: {recommendations_summary}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b570b63d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating comprehensive metrics report...\n",
      "Metrics report saved: /home/sirin/BIGDATA/quick-result/optimization_metrics_20251120_163355.json\n",
      "\n",
      "=== OPTIMIZATION METRICS ===\n",
      "{\n",
      "  \"timestamp\": \"20251120_163355\",\n",
      "  \"data_summary\": {\n",
      "    \"pickup_total_orders\": 531115,\n",
      "    \"delivery_total_orders\": 472419,\n",
      "    \"pickup_test_orders\": 106223,\n",
      "    \"delivery_test_orders\": 94484,\n",
      "    \"pickup_cities\": 5,\n",
      "    \"delivery_cities\": 3\n",
      "  },\n",
      "  \"pickup_model\": {\n",
      "    \"test_loss\": 0.00017407411360181868,\n",
      "    \"test_mae\": 0.011246351525187492,\n",
      "    \"test_mse\": 0.00017407411360181868,\n",
      "    \"avg_efficiency_score\": 0.20702911406238345,\n",
      "    \"predicted_avg_efficiency\": 0.2008327841758728\n",
      "  },\n",
      "  \"delivery_model\": {\n",
      "    \"test_loss\": 0.00016298131959047168,\n",
      "    \"test_mae\": 0.007678888738155365,\n",
      "    \"test_mse\": 0.00016298131959047168,\n",
      "    \"avg_efficiency_score\": 0.37366863229853275,\n",
      "    \"predicted_avg_efficiency\": 0.38024434447288513\n",
      "  },\n",
      "  \"optimization_impact\": {\n",
      "    \"pickup_test_improvement_potential\": 0.0060890428721904755,\n",
      "    \"delivery_test_improvement_potential\": -0.005920326337218285,\n",
      "    \"high_priority_pickup_routes\": 52913,\n",
      "    \"high_priority_delivery_routes\": 32612\n",
      "  },\n",
      "  \"files_exported\": {\n",
      "    \"pickup_model\": \"/home/sirin/BIGDATA/quick-result/pickup_optimizer_model_20251120_163355.h5\",\n",
      "    \"delivery_model\": \"/home/sirin/BIGDATA/quick-result/delivery_optimizer_model_20251120_163355.h5\",\n",
      "    \"artifacts\": \"/home/sirin/BIGDATA/quick-result/preprocessing_artifacts_20251120_163355.pkl\",\n",
      "    \"pickup_results\": \"/home/sirin/BIGDATA/quick-result/pickup_optimization_results_20251120_163355.csv\",\n",
      "    \"delivery_results\": \"/home/sirin/BIGDATA/quick-result/delivery_optimization_results_20251120_163355.csv\",\n",
      "    \"recommendations\": \"/home/sirin/BIGDATA/quick-result/recommendations_summary_20251120_163355.csv\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Generate comprehensive metrics report\n",
    "print(\"Generating comprehensive metrics report...\")\n",
    "\n",
    "# Calculate improvement potential only on test sets\n",
    "pickup_test_improvement = float((y_test_pickup - y_pred_pickup.flatten()).mean())\n",
    "delivery_test_improvement = float((y_test_delivery - y_pred_delivery.flatten()).mean())\n",
    "\n",
    "metrics_report = {\n",
    "    'timestamp': timestamp,\n",
    "    'data_summary': {\n",
    "        'pickup_total_orders': len(pickup_processed),\n",
    "        'delivery_total_orders': len(delivery_processed),\n",
    "        'pickup_test_orders': len(y_test_pickup),\n",
    "        'delivery_test_orders': len(y_test_delivery),\n",
    "        'pickup_cities': pickup_processed['from_city_name'].nunique(),\n",
    "        'delivery_cities': delivery_processed['from_city_name'].nunique()\n",
    "    },\n",
    "    'pickup_model': {\n",
    "        'test_loss': float(pickup_test_loss),\n",
    "        'test_mae': float(pickup_test_mae),\n",
    "        'test_mse': float(pickup_test_mse),\n",
    "        'avg_efficiency_score': float(pickup_processed['efficiency_score'].mean()),\n",
    "        'predicted_avg_efficiency': float(y_pred_pickup.mean())\n",
    "    },\n",
    "    'delivery_model': {\n",
    "        'test_loss': float(delivery_test_loss),\n",
    "        'test_mae': float(delivery_test_mae),\n",
    "        'test_mse': float(delivery_test_mse),\n",
    "        'avg_efficiency_score': float(delivery_processed['efficiency_score'].mean()),\n",
    "        'predicted_avg_efficiency': float(y_pred_delivery.mean())\n",
    "    },\n",
    "    'optimization_impact': {\n",
    "        'pickup_test_improvement_potential': pickup_test_improvement,\n",
    "        'delivery_test_improvement_potential': delivery_test_improvement,\n",
    "        'high_priority_pickup_routes': int((pickup_recommendations['priority'] == 'High').sum()),\n",
    "        'high_priority_delivery_routes': int((delivery_recommendations['priority'] == 'High').sum())\n",
    "    },\n",
    "    'files_exported': {\n",
    "        'pickup_model': pickup_model_path,\n",
    "        'delivery_model': delivery_model_path,\n",
    "        'artifacts': artifacts_path,\n",
    "        'pickup_results': pickup_export,\n",
    "        'delivery_results': delivery_export,\n",
    "        'recommendations': recommendations_summary\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save metrics report\n",
    "metrics_path = os.path.join(OUTPUT_PATH, f'optimization_metrics_{timestamp}.json')\n",
    "with open(metrics_path, 'w') as f:\n",
    "    json.dump(metrics_report, f, indent=2)\n",
    "\n",
    "print(f\"Metrics report saved: {metrics_path}\")\n",
    "print(\"\\n=== OPTIMIZATION METRICS ===\")\n",
    "print(json.dumps(metrics_report, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b453ddfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "DEEP LEARNING ROUTE OPTIMIZATION - SUMMARY\n",
      "============================================================\n",
      "\n",
      "✓ Data Loaded:\n",
      "  - Pickup orders: 531,115\n",
      "  - Delivery orders: 472,419\n",
      "\n",
      "✓ Models Trained:\n",
      "  - Pickup model layers: 13\n",
      "  - Delivery model layers: 13\n",
      "\n",
      "✓ Model Performance:\n",
      "  - Pickup MAE: 0.011246\n",
      "  - Delivery MAE: 0.007679\n",
      "\n",
      "✓ Optimization Opportunities:\n",
      "  - High priority pickup routes: 52,913\n",
      "  - High priority delivery routes: 32,612\n",
      "\n",
      "✓ Output Files Saved to: /home/sirin/BIGDATA/quick-result/\n",
      "  1. delivery_optimization_results_20251120_163355.csv\n",
      "  2. delivery_optimizer_model_20251120_163355.h5\n",
      "  3. pickup_optimization_results_20251120_163355.csv\n",
      "  4. pickup_optimizer_model_20251120_163355.h5\n",
      "  5. preprocessing_artifacts_20251120_163355.pkl\n",
      "  6. recommendations_summary_20251120_163355.csv\n",
      "\n",
      "============================================================\n",
      "Optimization Complete!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Final summary and verification\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DEEP LEARNING ROUTE OPTIMIZATION - SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\n✓ Data Loaded:\")\n",
    "print(f\"  - Pickup orders: {len(pickup_processed):,}\")\n",
    "print(f\"  - Delivery orders: {len(delivery_processed):,}\")\n",
    "\n",
    "print(\"\\n✓ Models Trained:\")\n",
    "print(f\"  - Pickup model layers: {len(pickup_model.layers)}\")\n",
    "print(f\"  - Delivery model layers: {len(delivery_model.layers)}\")\n",
    "\n",
    "print(\"\\n✓ Model Performance:\")\n",
    "print(f\"  - Pickup MAE: {pickup_test_mae:.6f}\")\n",
    "print(f\"  - Delivery MAE: {delivery_test_mae:.6f}\")\n",
    "\n",
    "print(\"\\n✓ Optimization Opportunities:\")\n",
    "print(f\"  - High priority pickup routes: {int((pickup_recommendations['priority'] == 'High').sum()):,}\")\n",
    "print(f\"  - High priority delivery routes: {int((delivery_recommendations['priority'] == 'High').sum()):,}\")\n",
    "\n",
    "print(\"\\n✓ Output Files Saved to: /home/sirin/BIGDATA/quick-result/\")\n",
    "output_files = sorted(os.listdir(OUTPUT_PATH))\n",
    "for i, file in enumerate(output_files[-10:], 1):  # Show last 10 files\n",
    "    print(f\"  {i}. {file}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Optimization Complete!\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
