{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a616f395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== HDFS Directory Structure ===\n",
      "\n",
      "├── [DIR] bigdata\n",
      "    ├── [DIR] Datapack\n",
      "        ├── [DIR] Delivery\n",
      "        ├── [DIR] Inventory\n",
      "        ├── [DIR] PickUp\n",
      "        ├── [DIR] Roadmap\n",
      "    ├── [DIR] output\n",
      "        ├── combined_all_data.csv\n",
      "\n",
      "=== /bigdata Contents ===\n",
      "Datapack                       [DIR  ] Size: 0 bytes\n",
      "output                         [DIR  ] Size: 0 bytes\n"
     ]
    }
   ],
   "source": [
    "from hdfs import InsecureClient\n",
    "\n",
    "# Initialize HDFS client\n",
    "hdfs_client = InsecureClient(\"http://localhost:9870\", user=\"root\")\n",
    "\n",
    "# List all directories in HDFS\n",
    "print(\"=== HDFS Directory Structure ===\\n\")\n",
    "\n",
    "def list_hdfs_tree(path, indent=0):\n",
    "    \"\"\"Recursively list HDFS directory structure\"\"\"\n",
    "    try:\n",
    "        contents = hdfs_client.list(path)\n",
    "        for item in contents:\n",
    "            full_path = f\"{path}/{item}\" if path != \"/\" else f\"/{item}\"\n",
    "            try:\n",
    "                status = hdfs_client.status(full_path)\n",
    "                is_dir = status['type'] == 'DIRECTORY'\n",
    "                prefix = \"├── \" if not is_dir else \"├── [DIR] \"\n",
    "                print(\" \" * indent + prefix + item)\n",
    "                \n",
    "                # Recursively list subdirectories (limit depth)\n",
    "                if is_dir and indent < 6:\n",
    "                    list_hdfs_tree(full_path, indent + 4)\n",
    "            except:\n",
    "                print(\" \" * indent + \"├── \" + item)\n",
    "    except Exception as e:\n",
    "        print(f\"Error listing {path}: {e}\")\n",
    "\n",
    "# Start from root\n",
    "list_hdfs_tree(\"/\")\n",
    "\n",
    "# Get detailed info about /bigdata\n",
    "print(\"\\n=== /bigdata Contents ===\")\n",
    "try:\n",
    "    contents = hdfs_client.list(\"/bigdata\")\n",
    "    for item in contents:\n",
    "        full_path = f\"/bigdata/{item}\"\n",
    "        status = hdfs_client.status(full_path)\n",
    "        file_type = \"DIR\" if status['type'] == 'DIRECTORY' else \"FILE\"\n",
    "        size = status.get('size', 0)\n",
    "        print(f\"{item:30} [{file_type:5}] Size: {size:,} bytes\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38fe0dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== HDFS Directory Structure ===\n",
      "\n",
      "├── [DIR] Datapack\n",
      "    ├── [DIR] Delivery\n",
      "        ├── (4.52 MB) delivery_jl.csv\n",
      "        ├── (30.07 MB) delivery_yt.csv\n",
      "        ├── (138.35 MB) delivery_cq.csv\n",
      "        ├── (217.50 MB) delivery_sh.csv\n",
      "        ├── (273.60 MB) delivery_hz.csv\n",
      "    ├── [DIR] PickUp\n",
      "        ├── (41.77 MB) pickup_jl.csv\n",
      "        ├── (181.38 MB) pickup_yt.csv\n",
      "        ├── (181.70 MB) pickup_cq.csv\n",
      "        ├── (217.76 MB) pickup_sh.csv\n",
      "        ├── (320.26 MB) pickup_hz.csv\n",
      "    ├── [DIR] Roadmap\n",
      "        ├── (221.01 MB) roads.csv\n",
      "    ├── [DIR] Inventory\n",
      "        ├── (4.26 KB) product_info.csv\n",
      "        ├── (84.77 MB) product_target_for_shop.csv\n",
      "        ├── (111.55 MB) shop_info_with_geo.csv\n",
      "├── [DIR] output\n",
      "    ├── (1.35 MB) combined_all_data.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Display the uploaded HDFS structure with accurate file sizes\n",
    "import subprocess\n",
    "import json\n",
    "\n",
    "print(\"=== HDFS Directory Structure ===\\n\")\n",
    "\n",
    "def parse_hdfs_ls_output(path):\n",
    "    \"\"\"Parse hdfs dfs -ls -R output to get accurate file information\"\"\"\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            ['hdfs', 'dfs', '-ls', '-R', path],\n",
    "            capture_output=True,\n",
    "            text=True\n",
    "        )\n",
    "        \n",
    "        if result.returncode != 0:\n",
    "            print(f\"Error: {result.stderr}\")\n",
    "            return {}\n",
    "        \n",
    "        # Parse the output\n",
    "        file_info = {}\n",
    "        for line in result.stdout.strip().split('\\n'):\n",
    "            if not line or 'total' in line:\n",
    "                continue\n",
    "            \n",
    "            parts = line.split()\n",
    "            if len(parts) >= 8:\n",
    "                # parts[4] is size, parts[7] is full path\n",
    "                size = int(parts[4])\n",
    "                full_path = parts[7]\n",
    "                file_info[full_path] = {\n",
    "                    'size': size,\n",
    "                    'is_dir': line.startswith('d')\n",
    "                }\n",
    "        \n",
    "        return file_info\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing HDFS output: {e}\")\n",
    "        return {}\n",
    "\n",
    "def print_tree_with_sizes(path, indent=0, file_info=None):\n",
    "    \"\"\"Print HDFS tree with accurate sizes\"\"\"\n",
    "    if file_info is None:\n",
    "        file_info = {}\n",
    "    \n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            ['hdfs', 'dfs', '-ls', path],\n",
    "            capture_output=True,\n",
    "            text=True\n",
    "        )\n",
    "        \n",
    "        if result.returncode != 0:\n",
    "            return\n",
    "        \n",
    "        lines = [l for l in result.stdout.strip().split('\\n') if l]\n",
    "        \n",
    "        for line in sorted(lines):\n",
    "            if 'total' in line or not line.strip():\n",
    "                continue\n",
    "            \n",
    "            parts = line.split()\n",
    "            if len(parts) >= 8:\n",
    "                is_dir = line.startswith('d')\n",
    "                size = int(parts[4])\n",
    "                filename = parts[7].split('/')[-1]\n",
    "                full_path = parts[7]\n",
    "                \n",
    "                if is_dir:\n",
    "                    prefix = \"├── [DIR] \"\n",
    "                    print(\"    \" * indent + prefix + filename)\n",
    "                    # Recursively list subdirectories\n",
    "                    if indent < 3:\n",
    "                        print_tree_with_sizes(full_path, indent + 1, file_info)\n",
    "                else:\n",
    "                    # Format size in human-readable format\n",
    "                    if size >= 1024**3:\n",
    "                        size_str = f\"{size / (1024**3):.2f} GB\"\n",
    "                    elif size >= 1024**2:\n",
    "                        size_str = f\"{size / (1024**2):.2f} MB\"\n",
    "                    elif size >= 1024:\n",
    "                        size_str = f\"{size / 1024:.2f} KB\"\n",
    "                    else:\n",
    "                        size_str = f\"{size} bytes\"\n",
    "                    \n",
    "                    prefix = f\"├── ({size_str})\"\n",
    "                    print(\"    \" * indent + prefix + \" \" + filename)\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "# Start from /bigdata\n",
    "print_tree_with_sizes(\"/bigdata\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
